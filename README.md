# Kenya_tour_inteligence_API

A Retrieval-Augmented Generation (RAG) API that enables users to ask travel-related questions and receive context-aware answers grounded in curated Kenyan tourism data. This system combines semantic search (ChromaDB + embeddings) with large language models (Groq LLM) to provide accurate, engaging, and source-backed responses.

## Overview

Instead of generating answers from general knowledge, this system:
-	Embeds curated tourism documents.
-	Stores them in a vector database.
- Retrieves the most relevant documents for a user query.
- Uses an LLM to generate answers strictly from retrieved context.
- Returns both the answer and the source references.

  ##### This ensures grounded, explainable responses.

## Architecture

- ### User Query

     â†“
- ### SentenceTransformer Embedding (BAAI/bge)
  
   â†“
- ### ChromaDB Similarity Search
  
   â†“
- ### Context Assembly
 
   â†“
- ### Groq LLM (Llama Model)
 
    â†“
- ### Structured JSON Response (Answer + Sources)



## Tech Stack

- FastAPI â€” API framework
- ChromaDB â€” Vector database
- SentenceTransformers (BAAI/bge) â€” Embedding model
-	Groq API â€” LLM inference
- Python 3.10+

## ğŸ“‚ Project Structure
                                                                                                                                
- â”œâ”€â”€ app.py                # FastAPI application
- â”œâ”€â”€ rag_service.py        # Retrieval + generation pipeline
- â”œâ”€â”€ chroma_db/            # Persistent vector database
- â”œâ”€â”€ .env                  # Environment variables
- â””â”€â”€ requirements.txt


## API Endpoints

GET /
Health check endpoint.
- Returns:
         
      {"message": "TOUR API is running"}

POST /ask

Submit a tourism-related question.

- Request:

       { "question": "Best wildlife experiences near Nairobi?"}

- Response

      {"answer": "...",
      "sources": ["nairobi_national_park.pdf"]}


## ğŸ” Retrieval Process
  1. User query is embedded using BGE model.
   
  2.	Embedding is normalized for cosine similarity.

  3.	ChromaDB retrieves top-k similar documents.
  
  4.	Retrieved content forms structured context.
  
  5.	LLM generates answer constrained to that context.
  

- This prevents hallucination and ensures grounded outputs.

â¸»

## ğŸ¯ Key Features
 
  â€¢	Persistent vector storage 
  
  â€¢	Context-grounded LLM responses
  
  â€¢	Source attribution
  
  â€¢	Structured JSON API
  
  â€¢	Easily extensible document ingestion pipeline

â¸»

## ğŸ“ˆ Future Improvements

 â€¢	Cross-encoder reranking for improved retrieval precision
  
 â€¢	Query expansion for better recall
  
 â€¢	Redis caching for frequent queries
  
 â€¢	Metadata filtering by location/category
  
 â€¢	Async streaming responses

â¸»

## ğŸ§© Use Cases

 â€¢	Tourism chatbots
  
 â€¢	Travel discovery assistants
  
 â€¢	Government tourism portals
  
 â€¢	Hotel and attraction discovery systems












  
